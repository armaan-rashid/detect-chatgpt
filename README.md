# DetectChatGPT

This is an implementation of a zero-shot detector for ChatGPT text, based on Eric Mitchell's original [DetectGPT](https://github.com/eric-mitchell/detect-gpt). You can run our experiments if you want or take this code and run it on new datasets and with different query models. 

The way the detector works is to first perturb a given piece of text (we found 100 times works best) little bits at a time (we found 2 words at a time, with 15% changed, is best). Then the probability of the original text and its perturbations is measured per token and averaged. If the perturbations are consistently lower probability than the original text, we tend to 'guess' that the text is ChatGPT generated, otherwise we tend to 'guess' it's human. The essential assumption behind this is that human text is not spit out one high-probability token at a time according to the trained probability distribution of an LLM. There's a lot more details in the paper.

**The original contribution of our project** is to use models other than ChatGPT to do this probability querying, since at the time we made this, ChatGPT's log probabilities were not accessible through the OpenAI API though this may not be true by the time you read this. We bafflingly found that using GPT-2 works best (even better than GPT-3!) for querying if texts are generated by ChatGPT or not. We think this _might_ be because we perturbed so little at a time that the perturbations are essentially just swapping synonyms, so any model that has an internal distribution over synonyms similar to ChatGPT's would work well at this, but haven't fully proved this. 

The datasets we used are in the respective files, and pre-generated Perturbations are here as well since the inference to generate them can be quite expensive. detect_chatgpt.py is the main script: run it with -h and it will tell you how to use it to perform experiments. perturb.py, data_processing.py, data_querying.py are also scripts if you want to just perturb data, process data, or get data from ChatGPT, respectively.

Much of the code here is a heavily adapted and refactored version from Eric Mitchell's original [DetectGPT](https://github.com/eric-mitchell/detect-gpt). If you want to use the code and functionality here, please also cite the original DetectGPT and include Mitchell's MIT License (which in his repo and ours) in your use of the code. This project was completed in collaboration with [Julia Park](https://profiles.stanford.edu/196008) for the Winter 2023 edition of CS224N at Stanford.
